\section{Multi-index sample selection} \label{Section:Multi-indexSS}

This section develops a structural empirical model to estimate the direct (or causal) repayment effect of project correlation, net of sorting bias. Technically, the equilibrium groups constitute a self-selected sample.\footnote{\citet[Chapter 17]{Wooldridge2002} provides a comprehensive textbook treatment of sample selection models.} The selection problem at hand differs substantially from that in \citet{Heckman1979}, who proposes a two-stage correction. The latter entails the estimation of the selection and outcome equations simultaneously and explicitly models the dependence structure of the error terms.


\subsection{Problem statement} 

In the four-borrower example from Section \ref{Section:Example}, the first-stage selection mechanism that determines which borrower groups are observed (and which are not) is a one-sided matching game and not a simple discrete choice as in the Heckman model. A discrete choice model assumes that an observed match reveals group partners' preferences over each other. However, the observed matching is the outcome of complex interactions and conflicts of interest between the players in the market. 

To make this point clearer, consider the example in Section \ref{Section:Example} where preferences are aligned and any borrower strictly prefers matching with partner $A$ or $B$ over $C$ or $D$. Assume we observe the match of agents $C$ and $D$ in a market of four borrowers $A$, $B$, $C$ and $D$. With a discrete choice model, we would infer that $C$'s choice of partner $D$ suggests that $u_{C,D}>u_{C,A}$. This restriction on the latent match valuations can then be used to derive the likelihood. However, such a conclusion has potential flaws in matching markets. In such markets, players $B$, $C$ and $D$ compete over a match with borrower $A$. If borrower $A$ prefers to match with $B$ instead of $C$, then we observe the match $CD$ from the example although it may well hold that $u_{C,A}>u_{C,D}$. In particular, borrowers can only choose from the set of partners who would be willing to form a match with them. However, we do not observe the players' relevant choice sets. This makes direct inference based on a discrete choice model %observed choices 
impossible, even if it accounts for social interactions such as the models in \citet{Brock2007} and \citet{Ciliberto2009}.



In response to this problem, \citet{Sorensen2007b} generalises the single-index Heckman sample selection model to multi-index sample selection models that allow for selection based on game theoretical models by relaxing the index property. The index property requires that two matches, such as $AB$ and $CD$, that have the same probability of being observed also have the same conditioning of unobserved characteristics. This requirement fails in matching markets. Here, for safe types $A$ and $B$ the unobserved characteristics are truncated from \textit{below} since they would be unable to match with a safe type if their unobserved characteristics were low. Following the same logic, for risky types $C$ and $D$ the unobserved characteristics are truncated from \textit{above}. 

In matching markets, therefore, the index property is violated and a multi-index selection model is called for. 
This model is a system of two equations. The first equation determines when the outcome is observed, while the second equation determines the outcome. %, $Y$.


\subsection{Structural empirical model} 

The first part of the structural model is the selection equation. The selection process can be written as the following system of match equations
\begin{eqnarray} \label{Eqn:ValuationEquation}
V_G &=& W_G\alpha + \eta_G.
\end{eqnarray}
There are $|\Omega|$ equations, where $\Omega$ is the set of feasible groups in the market. $V \in \mathbb R^{|\Omega|}$ is a vector of latents and $W \in \mathbb R^{|\Omega|\times k}$ a matrix of $k$ characteristics for all feasible groups. $\alpha \in \mathbb R^k$ is a parameter vector and $\eta \in \mathbb R^{|\Omega|}$ a vector of random errors. 
Whether a group, and therefore its outcome $Y_G$, is observed in equilibrium is indicated by $D_G = 1\left[ V_G \in \Gamma_{\mu} \right]$. This is an indicator function with $D_G=1$ if $Y_G$ is observed, and 0 otherwise. $Y_G$ is observed iff a group is part of the equilibrium matching $\mu$ in the market. That is, its group valuation is in the set of valuations $\Gamma_{\mu}$ that satisfy the equilibrium condition.\footnote{The classical \citet{Heckman1979} model is a special case where $D_G=1[V_G\geq 0]$ and the set of feasible valuations is simply $\Gamma = [0,+\infty )$.}
This set of valuations is the link between the structural empirical model and the equilibrium characterisations derived in \citet{Klein2015a} (for non-transferable utility) and Proposition \ref{Prop:EquConditionTU} (for transferable utility) in Appendix \ref{Appendix:Equilibrium}. 
With $V \in \mathbb R^{|\Omega|}$, the vector of all valuations in the market, %The set of valuations for which a given matching $\mu$ is the stable matching is $\Gamma_{\mu} \subset \mathbb R^{|\Omega|}$. The condition in Propositions \ref{Prop:EquConditionNTU} (for non-transferable utility) and \ref{Prop:EquConditionTU} (for transferable utility) can then be stated as
the equilibrium condition can be written as a collection of inequalities that give upper and lower bounds on the match valuations as follows
\begin{eqnarray} \label{PropositionNTU}
V \in \Gamma_{\mu} \Leftrightarrow \left[ V_G < \overline{V_G} \ \forall G \notin \mu \right] \Leftrightarrow \left[ V_G > \underline{V_G} \ \forall G \in \mu \right].
\end{eqnarray}
%Whether a group-outcome $Y$ is observed therefore depends on observables, $W$, and unobservables, captured by $\eta$, in the selection equation.
Substitution of the match valuations in Eqn \ref{Eqn:ValuationEquation} into the equilibrium condition above, allows us to state the condition on the error terms
\begin{eqnarray}
\mu \text{ is stable} \Leftrightarrow \eta \in \Gamma_{\mu} - W\alpha.
\end{eqnarray}
The likelihood of the matching model is then
\begin{eqnarray}
L\left(\mu; \alpha\right) = \mathbb P\left( \eta \in \Gamma_{\mu} - W\alpha \right) = \int 1\left[ \eta \in \Gamma_{\mu} - W\alpha \right] dF(\eta),
\end{eqnarray}
where 1[$\cdot$] is the indicator function and estimates for $\alpha$ could, in principle, be obtained by maximising this function. When several independent matching markets are observed, the likelihood is the product over these markets. To normalise parameter level, the constant term is excluded from $W.$

The second part of the model is the outcome equation. The binary outcome is given as $Y_G=1[Y^*_G > 0]$, where the latent group outcome variable $Y^*_G$ is
\begin{eqnarray} \label{Eqn:OutcomeEquation}
Y^*_G &=& X_G\beta + \varepsilon_G,
\end{eqnarray}
with $\varepsilon_G:=\delta\eta_G + \zeta_G$, where $\zeta_G$ is a random error. This specification allows for a linear relationship between the error terms in the selection and outcome equation with covariance $\delta$. The design matrices $X\in\mathbb R^{|\mu|}$ and $W\in\mathbb R^{|\Omega|}$ do not necessarily contain distinct explanatory variables.



\subsection{Distribution of error terms} 

Figure \ref{Fig:The structural model} summarises the structural model. If there are unobservables, captured in the error term, that determine both match valuation (the decision who matches with whom in the market) and the outcome, then $\eta$ and $\varepsilon$ are correlated and we have an endogeneity problem.

\begin{figure}[hbtp!]
  \begin{center}
    \begin{minipage}[c]{0.3\linewidth}
\centering %\hfill
      \caption{The structural empirical model. \\ - $X_{G\notin \mu}$ characteristics of non-equilibrium groups\\ - $X_{G\in \mu}$ characteristics of equilibrium groups \\ - $D_{G\in\mu}$ equ.\ indicator\\ - $Y_{G\in \mu}$ equ.\ outcome \\  - $\eta, \varepsilon$ correlated latents} 
      \label{Fig:The structural model}
    \end{minipage}
    \begin{minipage}[c]{0.6\linewidth}
\centering
\begin{tikzpicture}[domain=0:10]
[bend angle=45,
pre/.style={<-,shorten <=1pt,>=stealth',semithick},
post/.style={->,shorten >=1pt,>=stealth',semithick}]

\draw plot (0,5) node{$X_{G\notin \mu}, \eta_{G\notin\mu}$};

\draw[->] (1,5) -- (2,5);
\draw plot (3,5) node{$D_{G\in\mu}$};  

\draw[<-] (3.25,4.5) -- (4.25,3.5);
\draw plot (4.5,3) node{$X_{G \in \mu}$}; 


\draw[<-] (3.25,5.5) -- (4.25,6.5); 
\draw plot (4.5,6.75) node{$\eta_{G\in\mu}$};

\draw plot (6,5) node{$Y_{G\in \mu}$};  
\draw[->] (4.75,3.5) -- (5.75,4.5); 
\draw[<-] (6.25,5.5) -- (7.25,6.5); 
\draw plot (7.5,6.75) node{$\varepsilon_{G\in\mu}$};  

\draw [dashed] (6.9,7) arc (75:105:4cm);
\end{tikzpicture}
    \end{minipage}
  \end{center}
\end{figure}

%\vspace{-0.5cm}

The joint distribution of $\varepsilon_G$ and $\eta_G$ is assumed bivariate normal with mean zero, and constant covariance $\delta$.
\begin{eqnarray} \label{Eqn:JointErrorTermDistribution}
\left( \begin{matrix} 
\varepsilon_G \\ 
\eta_G
\end{matrix} \right) \sim N
\left( 0, \left[ \begin{matrix} 
\sigma^2_{\xi} +\delta^2 & \delta \\ 
\delta & 1
\end{matrix} \right] \right)
\end{eqnarray}
Here, the variance of the error term of the outcome equation $\sigma^2_{\varepsilon}$ is $var(\delta\eta + \xi) = \delta^2 + \sigma^2_{\xi}$. To normalise parameter scale, the variance of $\eta$ and $\zeta$ is set to 1, which simplifies $\sigma^2_{\varepsilon}$ to $1 + \delta^2$ in the estimation. If the covariance $\delta$ were zero, the marginal distributions of $\varepsilon_G$ and $\eta_G$ would be independent and the selection problem would vanish. That is, the observed outcomes would be a random sample from the population of interest.


\subsection{Identification}

The structural model allows for correlation between $\varepsilon$ and $\eta$, and imposes necessary equilibrium conditions on the valuations of both observed and unobserved groups. The interaction in the market makes estimation computationally involved but overcomes the identification problem. 

Identification requires exogenous variation. In this model, it is the characteristics of the other agents in the market that provide the exogenous variation. To illustrate, recall the example in Section \ref{Section:Example} with valuation Eqn \ref{Eqn:ExampleSelectionEqn} and outcome Eqn \ref{Eqn:ExampleOutcomeEqn}. The characteristics in the outcome equation of group $AB$ are simply $X=(X_{AB})$. The characteristics in the selection equation are $W=(X_{AB}, X_{CD}, X_{AC}, X_{AD}, X_{BC}, X_{BD})$, and the independent elements of $W$ are then $W'=(X_{CD}, X_{AC}, X_{AD}, X_{BC}, X_{BD})$. The identifying assumption is thus that the characteristics of agents outside the match (those comprised in $W'$) are exogenous, i.e., uncorrelated with the error terms. Put differently, the exclusion restriction is that $D$ (which groups are observed in equilibrium) depends the characteristics of all agents in the market, while the outcome of the equilibrium groups only depends on the characteristics of the members of those groups.\footnote{This identification assumption also holds in the presence of aggregate shocks because shocks which are common across potential groups in a village do not affect group formation. In the TU model, for example, the equilibrium condition is $V_L + V_M > \max\{ V_{L'} + V_{M'}\}$, where the LHS is the match valuation of equilibrium groups and the RHS is the maximum of all counterfactual groups in the market. Observe that a common shock term, added on both sides, would simply cancel out. A similar argument can be made in the NTU model because aggregate shocks add a constant to all match valuations.}

In particular, other agents' characteristics are not used as instruments in a traditional sense. Rather than entering the selection equation directly, they pose restrictions on the match valuations by determining the bounds in the estimation.


\subsection{Estimation}

In the estimation, I follow \citet{Sorensen2007}, who uses Bayesian inference with a Gibbs sampling algorithm that performs Markov Chain Monte Carlo (MCMC) simulations from truncated normal distributions. The latent outcome and valuation variables, $Y^*$ and $V$, are treated as nuisance parameters  and sampled from truncated Normal distributions that enforce sufficient conditions for the draws to come from the equilibrium of the group formation game.  %\citep[p.30]{Fox2009}
For the posterior distributions, see \citet{Klein2015a}. For an illustration of the simulation of the posteriors, see Appendix \ref{Appendix:Simulation}.

%To illustrate, for the latent variable probit in the outcome equation, we draw $\zeta$ from the truncated, standard Normal distribution $N(0,1)[\zeta>-X\beta-\delta\eta]$ for $Y=1$ and from $N(0,1)[\zeta\leq -X\beta-\delta\eta]$ for $Y=0$ where $[-X\beta-\delta\eta]$ is the Iverson bracket, indicating truncation. %at zero from below and $[Y^*\leq 0]$ indicating truncation at zero from above.

The conjugate prior distributions of parameters $\alpha$, $\beta$ and $\delta$ are Normal and denoted by $N(\bar \alpha, \Sigma_{\alpha})$, $N(\bar \beta, \Sigma_{\beta})$ and $N(\bar \delta, \sigma^2_{\delta})$. In the estimation, the prior distributions of $\alpha$ and $\beta$ have mean zero and variance-covariance matrix $\Sigma_\beta=(\frac{1}{|\mu|}X'X)^{-1}$ and $\Sigma_\alpha=(\frac{1}{|\Omega|}W'W)^{-1}$. This is the widely studied and used g-prior \citep{Zellner1986}. For $\delta$, the prior distribution has mean zero and variance 10. For this parameter, the prior variance is at least 40 times larger than the posterior variance in all estimated models. This confirms that the prior is fairly uninformative.

Under the assumption of transferable utility, estimation is computationally complex due to the valuation of the equilibrium bounds. Here, estimation does not simply involve a maximisation of a given set of valuations as in \citet{Klein2015a}. Instead, the bounds in Eqns \ref{Eqn:UpperBoundTU} and \ref{Eqn:LowerBoundTU} derived in Appendix \ref{Appendix:Equilibrium} require a maximisation over the set of all feasible \textit{matchings} in the market. This involves solving a partitioning linear program.

In the context of this paper, with two groups per market, obtaining the bounds is relatively straightforward. The Bank for Agriculture and Agricultural Cooperatives (BAAC) data comprise 30 two-group villages and nine one-group villages, each with a maximum of 5 borrowers per group. For each two-group village we thus have up to ${10 \choose 5} = 252$ feasible groups and roughly $252 \times 30 = 7,560$ bounds per iteration to calculate. On a laptop with a quad core 2.90 GHz processor running the 64 bit version of \proglang{R} 3.1.1 under Ubuntu Linux, the estimator produces 800,000 iterations in under 20 minutes.\footnote{There are clear limitations to the feasibility of the TU estimation using larger data sets, however. For example, let the Bayesian estimator presented in this paper take more than a million iterations to converge on a given data set. \citet{Nauss2003} presents an optimising branch-and-bound algorithm for the related generalised assignment problem (GAP). Dependent on the problem, this algorithm can find an optimal assignment in less than one second. A linear programming algorithm can, in principle, be implemented based on a partitioning linear program \citep[see][]{Quint1991} to evaluate the upper bounds in Eqn \ref{Eqn:UpperBoundTU} and lower bounds in Eqn \ref{Eqn:LowerBoundTU} that satisfy the equilibrium conditions % branch and bound algorithm: http://mat.gsia.cmu.edu/orclass/integer/node12.html
Assuming the linear programming algorithm can evaluate a bound in just $0.7$ seconds, it would take $1,000,000 \times 7,560 \times 0.7$ seconds $\approx 167$ years to estimate the model. Even if one assumes a weaker stability concept -- \textit{individual stability} -- where only individuals (not coalitions) can block a matching, we would still have 27 feasible groups per village (the original 2 groups plus $5 \times 5 = 25$ one-for-one swaps) and thus $27\times 30 = 810$ bounds to evaluate per iteration.  If one further assumes that the number of necessary iterations decreases linearly with the number of bounds that need to be evaluated (taking the TU model estimated in this paper as a reference point), we would still require approximately $100,000 \times 810 \times 0.7$ seconds $\approx 1.8$ years.}

\newpage

